---
- hosts: localhost
  vars:
    project_root: "{{ playbook_dir }}/../../../.."
    kubelet_location: "https://dl.k8s.io/v1.16.2/kubernetes-node-windows-amd64.tar.gz"
    wmcb_exe: "wmcb.exe"

  tasks:
    - name: Create directory to store files to be used later
      tempfile:
        state: directory
      register: tmp_dir

    - name: Build WMCB
      when: wmcb_url is undefined
      block:
        - name: Build WMCB
          make:
            target: build
            chdir: "{{ project_root }}"

        - name: Move WMCB to temporary directory
          command: mv "{{ project_root }}/{{ wmcb_exe }}" "{{ tmp_dir.path }}/{{ wmcb_exe }}"

    - name: Gather required files
      block:
        - name: Download WMCB
          when: wmcb_url is defined
          get_url:
            url: "{{ wmcb_url }}"
            dest: "{{ tmp_dir.path }}/wmcb.exe"

        - name: Download Windows node kubelet
          get_url:
            url: "{{ kubelet_location }}"
            dest: "{{ tmp_dir.path }}/kube.tar.gz"

        - name: Extract kubernetes node binaries
          unarchive:
            src: "{{ tmp_dir.path }}/kube.tar.gz"
            dest: "{{ tmp_dir.path }}"

        - name: Grab kubelet from extracted directories
          copy:
            src: "{{ tmp_dir.path }}/kubernetes/node/bin/kubelet.exe"
            dest: "{{ tmp_dir.path }}/kubelet.exe"

        - name: Grab kube-proxy from extracted directories
          copy:
            src: "{{ tmp_dir.path }}/kubernetes/node/bin/kube-proxy.exe"
            dest: "{{ tmp_dir.path }}/kube-proxy.exe"

        - name: Create temporary cni directory
          file:
            path: "{{ tmp_dir.path }}/cni"
            state: directory

        - name: Get cni plugins
          unarchive:
            src: "https://github.com/containernetworking/plugins/releases/download/v0.8.2/cni-plugins-windows-amd64-v0.8.2.tgz"
            dest: "{{ tmp_dir.path }}/cni"
            remote_src: yes

- hosts: win
  vars:
    tmp_path: "{{ playbook_dir }}/tmp"
    hybrid_overlay_exe : "hybrid-overlay.exe"
    ovn_annotation: "{{ 'hostsubnet' if  ( cluster_version.stdout  == '4.3' ) else  'node-subnet' }}"

  tasks:
    - name: Create temporary directory
      win_tempfile:
        state: directory
      register: win_temp_dir

    - name: Display Windows temporary directory
      debug:
        msg: "Windows temporary directory: {{ win_temp_dir.path }}"

    - name: Copy required files to Windows host
      win_copy:
        src: "{{ hostvars['localhost']['tmp_dir']['path'] }}/"
        dest: "{{ win_temp_dir.path }}"

    - name: Get ignition file
      win_get_url:
        url: "https://api-int.{{ cluster_address }}:22623/config/worker"
        dest: "{{ win_temp_dir.path }}\\worker.ign"
        validate_certs: no

    - name: Get kubernetes version
      delegate_to: localhost
      shell: "oc version -o json | jq -r '.serverVersion.minor' | tr -d +"
      register: kubernetes_version

    # This translates a kubernetes version to an OpenShift version. This works under the assumption that each OpenShift
    # release corresponds with a kubernetes release. This is being done this way, and not with oc get clusterversion,
    # as OpenShift CI doesn't have the actual version attached to its clusters, instead replacing it with 0.0.1 and
    # information about the release creation date
    - name: Get cluster version
      delegate_to: localhost
      shell: |
        MINORVERSION={{ kubernetes_version.stdout }}
        BASEK8SVERSION=16
        BASEOPENSHIFTVERSION=3
        if [ \"$MINORVERSION\" -lt \"$BASEK8SVERSION\" ]; then
        echo unsupported kubernetes version; exit 1
        fi
        VERSIONINCREMENTS=$((MINORVERSION - BASEK8SVERSION))
        echo 4.$((BASEOPENSHIFTVERSION + VERSIONINCREMENTS))
        exit 0
      register: cluster_version

    # curl -s https://api.github.com/repos/openshift/windows-machine-config-operator/releases gets the list of all
    # releases, we use the cluster version from previous ansible task to select the release we need.
    - name: Get release
      delegate_to: localhost
      shell: |
        RELEASES="$(curl -s https://api.github.com/repos/openshift/windows-machine-config-operator/releases)"
        TAGNAME="$(echo $RELEASES | jq '.[]' | jq '.tag_name' | grep -i {{ cluster_version.stdout }} | sort -r | awk 'NR==1')"
        echo $RELEASES | \
        jq '.[] | select (.tag_name == '$TAGNAME')'
      register: release

    # The wmcb release tags are supposed to conform to the following semver format:
    # v<openshift-major-version>.<openshift-minor-version>.<wmcb_build_number>-<release_type>. For example, v4.4-1-alpha.
    # For a <openshift-major-version>.<openshift-minor-version>, there can be many wmcb builds available, for
    # example, OpenShift 4.4 can map to v4.4.1-alpha and v4.4.2-alpha, we will always pick up the latest build available
    # which is v4.4.2-alpha,
    # In future, when we cut beta and GA releases, the playbook should always go for GA version when available.
    - name: Get hybrid overlay url
      delegate_to: localhost
      shell: |
        echo '{{ release.stdout }}' | \
        jq ' .assets[] | select (.name == "{{ hybrid_overlay_exe }}" )' | \
        jq -r .browser_download_url
      register: hybrid_overlay_download_url

    - name: Get hybrid overlay exe
      win_get_url:
        url: "{{ hybrid_overlay_download_url.stdout }}"
        dest: "{{ win_temp_dir.path }}\\hybrid-overlay.exe"
        follow_redirects: all

    # We'll get the SHA associated with the hybrid_overlay.exe in the body of the release tag.
    - name: Get the SHA for the given binary. We assume that body of WMCB release has the info.
      delegate_to: localhost
      shell: |
        echo '{{ release.stdout }}' | \
        jq -r .body | \
        grep -i {{ hybrid_overlay_exe }}| \
        awk '{print $1}'
      register: hybrid_overlay_sha

    # TODO: Remove this, win_get_url already has checksum, we can use it.
    - name: Check hybrid overlay SHA256
      win_shell: "certutil -hashfile {{ win_temp_dir.path }}\\hybrid-overlay.exe sha256"
      register: hybrid_sha256
      failed_when: "hybrid_sha256.stdout_lines[1] != hybrid_overlay_sha.stdout "

    - name: Run bootstrapper
      win_shell: "{{ win_temp_dir.path }}\\wmcb.exe initialize-kubelet --ignition-file {{ win_temp_dir.path }}\\worker.ign --kubelet-path {{ win_temp_dir.path }}\\kubelet.exe"
      register: bootstrap_out

    - name: Check if bootstrap was successful
      fail:
        msg: "Bootstrapper error"
      when: '"Bootstrapping completed successfully" not in bootstrap_out.stderr'

    # Making a best effort to approve CSRs. Not failing until the actual `get node` call, in case the CSRs were approved elsewhere
    - name: Approve CSRs
      block:
        - name: Initial wait for bootstrap CSR
          pause:
            seconds: 30

        - name: Check for bootstrap CSR
          delegate_to: localhost
          shell: "oc get csr | awk '/system:serviceaccount:openshift-machine-config-operator:node-bootstrapper/ && /Pending/ {print $1}'"
          register: bootstrap_csrs
          until: bootstrap_csrs.stdout != ""
          retries: 2
          delay: 60
          ignore_errors: yes

        - name: Approve pending bootstrap CSRs
          delegate_to: localhost
          shell: "oc adm certificate approve {{ item }}"
          with_items: "{{ bootstrap_csrs.stdout_lines }}"
          ignore_errors: yes

        - name: Initial wait for node CSR
          pause:
            seconds: 30

        - name: Wait for node CSR
          delegate_to: localhost
          shell: "oc get csr | awk '/system:node:/ && /Pending/ {print $1}'"
          register: node_csrs
          until: node_csrs.stdout != ""
          retries: 2
          delay: 60
          ignore_errors: yes

        - name: Approve pending node CSRs
          delegate_to: localhost
          shell: "oc adm certificate approve {{ item }}"
          with_items: "{{ node_csrs.stdout_lines }}"
          ignore_errors: yes

    # Get the bootstrapped windows node name. We're using the IP address of the Windows VM created
    # in the inventory file and if the node has multiple internal IP's or external IP's it may not work well.
    # TODO: Move this to a more deterministic way of identifying the node we just bootstrapped
    - name: Get bootstrapped node name
      delegate_to: localhost
      shell: "oc get node -o wide |awk '/{{ inventory_hostname }}/ {print $1}'"
      register: node_name
      until: node_name.stdout != ""
      retries: 3
      delay: 5

    # Check if worker label is already applied to the Windows nodes bootstrapped via WMCB
    # We should always get a single node that we've bootstrapped recently, if not skip this
    # step
    - name: Check if worker label is already applied to the Windows nodes bootstrapped via WMCB
      delegate_to: localhost
      shell: "oc get node {{ node_name.stdout_lines[0] }} -o yaml | grep -i node-role.kubernetes.io/worker"
      ignore_errors: yes
      register: checklabels
      when: node_name.stdout_lines | length == 1

    # Apply worker label to the Windows nodes bootstrapped via WMCB
    - name: Label the Windows node that was just bootstrapped with worker labels
      delegate_to: localhost
      shell: "oc label node {{ node_name.stdout_lines[0] }} node-role.kubernetes.io/worker="
      when: node_name.stdout_lines | length == 1 and checklabels.rc == 1

    - name: Check if the hybrid overlay is running
      win_shell: "Get-Process -Name \"hybrid-overlay\""
      register: get_process
      failed_when:
        - 'get_process.stderr != ""'
        - '"Cannot find a process with the name" not in get_process.stderr'

    - name: Stop the hybrid overlay if it is running
      win_shell: "Stop-Process -Name \"hybrid-overlay\""
      when: 'get_process.stderr == ""'

    - name: Start the hybrid overlay
      win_shell: "Start-Process -NoNewWindow -FilePath \"{{  win_temp_dir.path }}\\hybrid-overlay.exe\" -ArgumentList \"--node  {{ node_name.stdout }} --k8s-kubeconfig c:\\k\\kubeconfig\""
      async: 60
      poll: 0
      register: async_results

    - name: Wait for the hybrid overlay
      delegate_to: localhost
      shell: "oc get nodes {{ node_name.stdout }} -o=jsonpath='{.metadata.annotations}'"
      register: overlay
      until: '"k8s.ovn.org/hybrid-overlay-distributed-router-gateway-mac" in overlay.stdout'
      retries: 12
      delay: 5

    - name: Create cni config directory
      win_file:
        path: "{{ win_temp_dir.path }}\\cni\\config"
        state: directory

    # Get the subnet associated with host. We assume the network operator object has been modified to
    # include hybrid overlay config
    - name: Get the subnet associated with host
      delegate_to: localhost
      shell: |
        oc get nodes {{ node_name.stdout}} \
        -o=jsonpath='{.metadata.annotations.k8s\.ovn\.org\/hybrid-overlay-{{ ovn_annotation }} }'
      register: ovn_host_subnet

    - name: Check that subnet associated with host is not empty
      fail:
        msg: Could not find node subnet
      when: ovn_host_subnet.stdout == ""

    # Get the service CIDR associated with the OpenShift network operator object. We assume that network always object
    # has atleast one entry as per defaulting at
    # https://github.com/openshift/installer/blob/master/pkg/types/defaults/installconfig.go#L18
    - name: Get the service CIDR associated with network object
      delegate_to: localhost
      # We're using the first element of the array for now. This may cause problems down the line with a more complex
      # network setup that has multiple service networks.
      shell: "oc get network.operator.openshift.io/cluster -o=jsonpath='{.spec.serviceNetwork[0]}'"
      register: service_network_cidr

    # Generate the cni.conf file to be transferred to the Windows host
    - name: Generate the cni config file
      win_template:
        src: templates/cni.j2
        dest: "{{ win_temp_dir.path }}\\cni\\config\\cni.conf"

    - name: Configure CNI
      win_shell: "{{ win_temp_dir.path }}\\wmcb.exe configure-cni --cni-dir=\"{{ win_temp_dir.path }}\\cni\" --cni-config=\"{{ win_temp_dir.path }}\\cni\\config\\cni.conf\""
      register: bootstrap_out

    - name: Check if CNI configuration was successful
      fail:
        msg: "CNI Configuration error"
      when: '"CNI configuration completed successfully" not in bootstrap_out.stderr'

    - name: Copy kube-proxy to C:\k
      win_copy:
        src: "{{ win_temp_dir.path }}\\kube-proxy.exe"
        dest: "C:\\k\\kube-proxy.exe"
        remote_src: yes

    - name: Copy required powershell script to the temporary directory
      win_copy:
        src: "powershell/hns.psm1"
        dest: "{{ win_temp_dir.path }}\\hns.psm1"

    - name: Get source-vip
      win_shell: 'Import-Module {{ win_temp_dir.path }}\\hns.psm1; $net = (Get-HnsNetwork | where { $_.Name -eq "OpenShiftNetwork" }); $endpoint = New-HnsEndpoint -NetworkId $net.ID -Name VIPEndpoint; Attach-HNSHostEndpoint -EndpointID $endpoint.ID -CompartmentID 1; (Get-NetIPConfiguration -AllCompartments -All -Detailed | where { $_.NetAdapter.LinkLayerAddress -eq $endpoint.MacAddress }).IPV4Address.IPAddress.Trim()'
      register: source_vip

    - name: Ensure kube-proxy Windows Service is not running
      win_service:
        name: "kube-proxy"
        state: absent

    - name: Start kube-proxy Windows Service
      win_service:
        name: "kube-proxy"
        path: "C:\\k\\kube-proxy.exe --windows-service --v=4 --proxy-mode=kernelspace --feature-gates=WinOverlay=true --hostname-override={{ node_name.stdout }} --kubeconfig=c:\\k\\kubeconfig --cluster-cidr={{ ovn_host_subnet.stdout }} --log-dir=c:\\k --logtostderr=false --network-name=OpenShiftNetwork --source-vip={{ source_vip.stdout | trim }} --enable-dsr=false"
        state: started
        start_mode: auto
        display_name: "kube-proxy"
        description: "OpenShift kube-proxy"
